{
  "hash": "8695d6580058c13707b5354776b0b76f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle-block-banner: true\ntitle: \"Unveiling the Drivers of Clean Air\"\nsubtitle: \"Analysis of Portland Air Quality (AQI)\"\ndate: \"2024-07-30\"\nformat:\n  html:\n    code-fold: true\n    code-tools:\n      source: repo\n      toggle: true\n      caption: none\n    smooth-scroll: true\n    toc: true\n    toc-title: Contents\n    number-sections: false\n    other-links:\n      - text: Airnow Open Data\n        href: https://www.airnow.gov\n    code-links:\n      - text: Sweetviz Analysis Report\n        icon: file-code\n        href: SWEETVIZ_REPORT.html\n    html-math-method: mathjax\n    css: styles.css\nexecute:\n  echo: false\n  warning: false\njupyter: python3\n---\n\n# Introduction\n\nOn October 30, 1948, the Donora High School Football team played through a dense smog to complete the game with hundreds of fans in the audience, despite very poor visibility. The team, fueled by resilience, took pride in playing through poor conditions, a testament to the high spirit of the small town. Soon after, calls to the town’s medical offices began flooding in, complaining of difficulty breathing and respiratory issues. Donora, Pennsylvania, was a town of metalworks, built by the American Steel and Wire company and the Donora Zinc Works company, which made up major parts of the town’s economy. The heavy smog and pollution clouds that covered the sky had been viewed as a sign of prosperity, owing to the industrial might that powered their economy. Within just twelve hours, seventeen people would be dead, 1440 seriously affected, and 4470 with mild to moderate conditions---almost half the town’s working population (Jacobs, Burgess, Abbott). \n\nThis event, known as the Donora Smog of 1948, prompted the country into taking a closer look at the negative impacts of air pollution. Widespread debate surrounding the event led to the first legislation aimed at regulating the air quality within the United States, ushering in a new era of tracking, combatting, and reversing the ill effects of poor air quality. \n\nThe quality of air we breathe has direct impacts on our health. We must understand the factors that contribute to poor air quality and how we individually and collectively contribute to these changes. Until we can visualize the impact we have on our atmosphere, we will continue behavior that negatively impacts the air around us. \n\nIn this project, we will focus on the key factors influencing air quality in Portland, Oregon. We aim to understand the complex interplay between various environmental and human-made factors that contribute to high air pollution levels. Initially, we were surprised to discover that Portland, the city we reside in, has some of the best air quality for a city of its size in the United States. This led us to narrow our focus to understanding the factors that contribute to these favorable outcomes in this city.\n\nOur project aims to develop and validate machine learning models to analyze the various factors influencing air quality. By focusing on Portland in comparison to other large US cities, we hope to find things Portland does that lead to the greater AQI outcomes. Our approach will consider a range of variables, including meteorological conditions, pollution sources, and transit systems. Through this analysis, we aim to provide actionable insights and recommendations for sustaining and improving air quality. By examining both the contributors to clean air and the sources of pollution, we can understand the factors affecting air quality and develop comprehensive strategies for enhancement.\n\n\n# Background\n\nFederal regulation of air quality in the United States began in 1955 with the Air Pollution Control Act. This new piece of legislation provided funding for initial research into air quality and pollution in the US. Building off this and privately funded research, Congress passed the Clean Air Act of 1963, establishing the first federal regulation for controlling air pollution. This act established a new federal program within the US Public Health Service, dedicated to the monitoring and control of air quality. In 1967, Congress passed the Air Quality Act, which introduced more federal oversight and enforcement policies, allowing extensive monitoring of interstate air pollution. This all led to the passage of the 1970 Clean Air Act, aimed at restricting and regulating emissions, measuring and reducing pollutant particles, and addressing upcoming pollution threats (Environmental Protection Agency).\n\nAlso established in 1970, the Environmental Protection Agency (EPA) implemented and monitored the requirements established by these rulings. The EPA's authority extended beyond federal lands and roads to include all companies operating within the United States. Enforcement authority was expanded to allow upholding these established standards, and prevent companies from circumventing the law.  Much of the improvement in the quality of air in the US over the past fifty years can be attributed to these regulations. In 1990, when deaths due to air quality were first measured, an estimated 135,000 Americans died. By 2010, that number had dropped to 71,000 (Zhang et al.). Despite the significant improvements led by the federal guidelines of the late 70s, nearly four in ten Americans still live in places where they are exposed to unhealthy air (American Lung Association).\n\nIn 1999, the EPA developed the Air Quality Index (AQI), creating an easily understood measurement of air quality. The AQI measures air pollution levels on a scale from 0 to 500, divided into six categories. A score of 0 to 50 represents good air quality which poses little or no risk to those breathing it in, while a score above 300 signifies emergency conditions, an extremely high risk which impacts everyone. This measurement is mainly derived from five major pollutants: ozone, particulate matter (2.5μm and 10μm), carbon monoxide, nitrogen dioxide, and sulfur dioxide (Airnow.gov). Poor air quality has been linked to a variety of diseases including respiratory infections, stroke, heart disease, lung cancer, and chronic obstructive pulmonary disease, among others (World Health Organization). An estimated seven million premature deaths annually can be attributed to air pollution, which equates to a global mean loss of life expectancy of 2.9 years, making it the largest environmental risk factor for disease and premature death (Fuller, Landrigan, Balakrishnan, et. al.). Thus, it is important to understand factors that contribute to poor air quality, and outcomes that can be attributed to the state of the AQI.\n\nThese harmful factors can originate from a variety of sources. Anything that releases a foreign substance into the air can lower the quality of the air. This includes smoking, vehicle exhaust, combustion processes for production and manufacturing, household cleaning products, appliances, central air and heating systems, agriculture pesticides, livestock, shipping and transportation, and much more. Individually, we can reduce our individual contributions by lowering our reliance on personal vehicles, watching our power usage, supporting companies that monitor and address their emissions, and more. However, there are many factors beyond our control. Larger pollutant sources, such as manufacturing and transportation, are often regulated to some extent but may still release significant amounts of pollutants into the atmosphere which we as individuals have no say over (Manisalidis, Stavropoulou, Stavropoulos, Bezirtzoglou). It is challenging to restrict and watch our personal contributions to the polluting of the environment without worrying about what others are doing. Measuring and analyzing the impact these pollutants have on air quality is a crucial step towards addressing these issues.\n\n\n# Methods\n\n## Tools Deployed\nPython will be the primary programming language used to conduct this analysis. We will also use R language in statistical applications where necessary.\n\nTo perform our analysis, we will employ NumPy and Pandas for data manipulation. Matplotlib and Seaborn for visualization, and Time Series forecasting algorithms such as Prophet and SARIMAX.\n\nWe will address data inconsistencies, missing values and ensure that data is in a tidy format.\n\nWe may need to normalize or standardize data if necessary and create new features through aggregation to enhance the model’s performance.\n\n## What is Prophet?\n\nProphet is an open-source forecasting tool developed by Meta, designed for forecasting time series data. It is suited for datasets with strong seasonal, monthly, weekly, or daily patterns, and it handles missing data and outliers well. We utilized prophet to gain a quick understanding of our AQI patterns, seeking to understand basic trends before conducting a more thorough analysis.\n\nKey features of Prophet include seasonality detection and holiday incorporation, while providing easy use and understanding for users. \nWe can use this software to get complex understanding from simple applications.\n\nTo conduct this analysis, we prepare data into a two column table, date and AQI. Prophet uses the trends of past data to highlight similarities over days of the year, weeks, months, and seasons. From this, prophet is able to generate its predictions, cross validate, and give performance metrics such as mean absolute percentage error to quantify the accuracy of the results.\n\n## What is SARIMAX algorithm?​​​​​​​​​​​​​​​\nThe most common method used in time series forecasting is known as the ARIMA model. We will use an extended version called SARIMAX (*Seasonal Auto Regressive Integrated Moving Averages with exogenous factor*)\n\n- The SARIMAX model is used when the data sets have seasonal cycles. \n- In the dataset concerning the air quality/AQI there is a seasonal pattern which we have explained in the above section.\n- SARIMAX is a model that can be fitted to time series data in order to better understand or predict future points in the time series\n- SARIMAX is particularly useful for forecasting time series data that exhibits both trends and seasonality.\n\nHere's a breakdown of its components:\n\nThere are three distinct integers (p,d,q) that are used to parametrize SARIMAX models. Because of that, ARIMA models are denoted with the notation SARIMAX(p,d,q).\n\nTogether these three parameters account for seasonality, trend, and noise in datasets:\n\n1. *Seasonality (S)*: Accounts for recurring patterns or cycles in the data.\n2. *AutoRegressive (AR)*: Uses past values to predict future values.\n3. *Integrated (I)*: Applies differencing to make the time series stationary.\n4. *Moving Average (MA)*: Uses past forecast errors in the prediction.\n5. *eXogenous factors (X)*: Incorporates external variables that may influence the forecast.\n\nWe are trying to find the right p, d, q hyperparameters to correctly forecast and predict the AQI values.\n\n# Metrics to Evaluate Machine Model Performance\n\n| Technique/Metric | Description | Purpose/Formula | Scenario: Cancer prediction |\n|------------------|-------------|-----------------|-------------------|\n| 1. Train-Test Split | Split the dataset into training and testing subsets | Assess model performance on unseen data to detect overfitting and ensure generalizability | Always used; crucial for unbiased evaluation of model performance |\n| 2. Cross-Validation | Divide data into k subsets and train the model k times, using a different subset as test set each time | Provides robust estimate of model performance by averaging results over multiple splits | Useful for smaller datasets or when data collection is expensive (e.g., rare cancer types) |\n| 3. Confusion Matrix | Table comparing predicted and actual values in classification | Metrics: True Positives (TP), True Negatives (TN), False Positives (FP), False Negatives (FN) | Fundamental for understanding model performance in classification tasks, like cancer detection |\n| 4. Accuracy | Ratio of correctly predicted instances to total instances | $\\frac{TP + TN}{TP + TN + FP + FN}$ | Used when classes are balanced; less suitable for rare cancer detection due to class imbalance |\n| 5a. Precision | Ratio of correctly predicted positive observations to total predicted positives | $\\frac{TP}{TP + FP}$ | Important when false positives are costly (e.g., unnecessary biopsies or treatments) |\n| 5b. Recall (Sensitivity) | Ratio of correctly predicted positive observations to all actual positive observations | $\\frac{TP}{TP + FN}$ | Critical in cancer detection to minimize false negatives (missed cancer cases) |\n| 5c. F1-Score | Harmonic mean of Precision and Recall | $2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}$ | Balances precision and recall; useful when seeking a compromise between false positives and false negatives |\n| 6. ROC Curve and AUC | ROC: Graph of true positive rate vs false positive rate at various thresholds. AUC: Area under ROC curve | Higher AUC indicates better model performance | Useful for comparing models and choosing optimal threshold, especially in diagnostic tests |\n| 7. Mean Absolute Error (MAE) | Average of absolute differences between predicted and actual values | $\\frac{1}{n} \\sum_{i=1}^{n} \\|y_i - \\hat{y}_i\\|$ | Used in regression tasks, e.g., predicting survival time; less sensitive to outliers than MSE |\n| 8a. Mean Squared Error (MSE) | Average of squared differences between predicted and actual values | $\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ | Used in regression; penalizes large errors more, suitable when large errors are particularly undesirable |\n| 8b. Root Mean Squared Error (RMSE) | Square root of MSE | $\\sqrt{\\text{MSE}}$ | Same as MSE, but in the original unit of the target variable, making it more interpretable |\n| 9. R-squared | Proportion of variance in dependent variable predictable from independent variables | $1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$ | Used in regression to assess overall fit; indicates how well the model explains the variance in the data |\n| 10a. Akaike Information Criterion (AIC) | Measures relative quality of statistical model for given data | $2k - 2\\ln(L)$ where $k$ is number of parameters and $L$ is likelihood | Used for model selection; helps prevent overfitting by penalizing complex models |\n| 10b. Bayesian Information Criterion (BIC) | Similar to AIC but with stronger penalty term for number of parameters | $k\\ln(n) - 2\\ln(L)$ where $n$ is number of observations | Also used for model selection; tends to favor simpler models compared to AIC |\n\n# Machine Learning AQI Time Series\n## How can we use Akaike Information Criteria (AIC)?\nUsed to measure of a statistical model, it quantifies:\n\n- The goodness of fit\n- The simplicity of the model into a single statistic\n- When comparing two models, the one with the lower AIC is generally \"better\"\n\nThe Akaike Information Criterion (AIC) is a measure used to compare different statistical models. It helps in model selection by balancing the goodness of fit and the complexity of the model. Here's how to interpret the AIC value:\n\n- *Lower AIC is Better*: A lower AIC value indicates a better-fitting model. It means the model has a good balance between accuracy and complexity.\n- *Comparative Measure*: AIC is most useful when comparing multiple models. The model with the lowest AIC among a set of candidate models is generally preferred.\n- *Penalty for Complexity*: AIC includes a penalty for the number of parameters in the model. This discourages overfitting by penalizing models that use more parameters without a corresponding improvement in fit.\n\n\n\n\n\n## Data Explaination\nThe data for this project was initially scattered across multiple sources and required significant organization and compilation. The focus of this project is on the air quality in Portland, Oregon, so various data sources were aggregated and processed to compare a variety of air quality indicators.\n\n## Air Quality Data:\nAir quality data, specifically AQI values, were obtained from the United States Environmental Protection Agency (EPA) pre-generated data files. The AQI values are calculated daily, based on a variety of factors including criteria gasses and measured pollutant concentrations, and measures how harmful breathing the air is. AQI is classified into one of six categories from ‘good’ to ‘hazardous’, each having long term health effects associated with it. The files were given daily on a county wide basis, separated into different files by year. \n\n## Meteorological Data:\nHistorical weather data was also sourced from the EPA database, measured by thousands of weather stations across the country. Measurements tracked include temperature, wind speed, air pressure, and humidity. Temperature is measured in degrees fahrenheit. Wind speed is measured in knots, which are defined as one nautical mile per hour (equivalent to approximately 1.15mph). Wind speed is important in air quality as winds can blow different pollutants around and move and spread wildfires. Pressure is measured in millibars, where 1013.25 millibars is the standard atmospheric pressure (Earth’s pressure at mean sea level). Finally, humidity is measured in percent relative humidity. This is the amount of water vapor in the air as a percentage of the maximum amount of water vapor possible at a given temperature. Humidity can make it more difficult to breathe and sweat, make the air feel hotter than it is, and prevent air pollutants from dispersing as easily. Indoors, high humidity can trap air, leading to the growth of mold and harmful bacteria. This data was given daily by city, separated into different files by year. Measurements were taken hourly, but pre-calculated in the source database, giving an average value over the twenty four hours and a maximum value.\n\n## Pollution Source Data:\nPollution data was again sourced from the EPA database, separated by criteria gasses (CO, NO2, O3, SO2), Toxins (lead), and particulate matter (PM2.5 and PM10). Criteria gas Carbon Monoxide is measured in parts per million, and is especially dangerous as it is both colorless and odorless. CO binds to hemoglobin in the blood, making the transportation of oxygen around the body more difficult. Nitrogen Dioxide is dangerous to breathe in at high levels. It can cause swelling in the throat, burning, reduced oxygenation of body tissues, and fluid build up in the lungs. It is released in many common combustion reactions including in cars, coal plants, and cigarettes. It is measured in parts per billion. Ozone can harm our ability to breathe, especially in older people, children, and people with asthma. It is measured in parts per million. Sulfur Dioxide, measured in parts per billion, can irritate the eyes, mucous membranes, skin, and respiratory tract. Lead is a toxin which can increase the risk of high blood pressure, cardiovascular problems, and complications during pregnancy. While exposure has gone down significantly in the recent decades after use in gasoline, it still remains a dangerous toxin to breathe in. It is measured in micrograms per cubic meter. PM2.5 and PM10 are particulate matter, small inhalable particles with diameters of 2.5 microns or smaller, and 10 microns or smaller respectively. PM2.5 includes all sorts of common particles, metals, and organic compounds. PM10 includes dust, pollen, molds, and other larger (but still very small) particles. Due to the variability of particles included in the PM classification, there are a wide range of negative health impacts that come from breathing in these particles. PM2.5 and PM10 are measured in micrograms per cubic meter.\n\nThis data was given daily by city, separated into different files by year. They are sourced from thousands of individual sources, which measure various selections of these pollution sources. Because of the variety of different pollutants being measured, there was a significant amount of missing data, especially from small towns. Measurements were taken hourly, pre-compiled into a daily average and maximum. \n\n## Transit Data:\nInformation on motor buses taken from the National Transit Database, produced by the Federal Transit Administration. Includes information of bus systems and ridership by city, separated by year. Data is recorded yearly, encompassing annual totals for information such as number of buses, total revenue, passengers, and miles driven for the respective city transit systems. Information was given in yearly CSVs, separated by the city transit system. For cities with multiple systems, data was combined. Only motorbus data was used, which may not be reflective of cities with other large methods of public transportation, such as the New York subway system.\n\n## Population Data:\nData on population and population density sourced from the Simplemaps United States Cities database, which is built from multiple sources including the U.S. Geological Survey and the U.S. Census Bureau. Data is updated as of May 6, 2024, reflecting very up to date information. \n\n# Data Processing\nThe data was downloaded in R. For information given in yearly CSV files, data was stacked vertically to include all years in our time frame. In all tables, relevant columns were selected and renamed, reducing the information being brought into our initial SQL database. R was connected and imported to PostgreSQL using the RPostgres package, and used to read, stack, select columns, and rename columns before being written into a PostgreSQL database. \n\n## Data Organization\nGiven the raw data available, the table structure was simplified compared to the original data sources. Data was organized in a star schema centered on the air_quality fact table. This table tracks AQI, pollutant, weather and toxin data daily for each location. The first dimension table is the dates table, a serialized list of dates from January 1st, 2015 to December 31st, 2022. Next, we have a locations dimension table, a serialized list of over 1400 cities and towns from around the country. These are labeled by the state, county, and city name, as well as the population and population density, allowing connection to information based on what is given. The aqi_category dimension table is a short list of AQI value categories (Good, Unhealthy, Hazardous, etc.) with their respective AQI value range as minimum and maximum values. \n\nFinally, the yearly_transit dimension table gives the information for the transit system of the respective city during the specified year attached in the fact table. This table seems counterproductive to not include the location or year of the specified line or even a reference id, but in keeping with star schema, it was decided that this was the best way to reference this information. Understanding the context of a specified line requires joining the table back to the fact table, and joining the location and date tables to that as well. \n\nEach table has a unique serialized primary key, and all dimension tables are connected via foreign key. Several additional indexes are included on columns that will be queried often. Finally, constraints have been added to limit unusual or impossible data.\n\nTracking these identifiers independently allows for accurate analysis of changes over time and across different areas, and allows adding new information should we need to update the database. (Figure 1) illustrates the resulting ERD structure using drawSQL.\n\n\nFigure 1.  \n\n![ERD Diagram](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/aqi_erd_final.png?raw=true)\n\n\n\n## Initial Exploratory Data Analysis (EDA)\nWe have a new dataset named metro_1mil.csv. This file was created using a SQL statement that joins all relevant tables, filtering for metropolitan areas with populations less than or equal to 1 million. This approach limits our EDA to mid-sized metropolitan cities, such as Portland, Oregon.\n\n\n\n## Visualization AQI Distribution\nLet's plot the AQI data distribution\n\n::: {#cell-plot-aqi .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/plot-aqi-output-1.png){#plot-aqi width=829 height=523}\n:::\n:::\n\n\n## Dataframe Shape\n\n\n\nThe DataFrame contains 147039 rows and 44 columns.\n\n# Exploring Oregon State: \n\n\n\nBy filtering our Dataframe for Oregon state, our DataFrame contains 2922 rows.\n\n# Features Engineering\n\n\n\n\n\n\n\nDate Column Preprocessing:\n\n- Converted the date column to DateTime objects for easier manipulation and analysis.\n- Extracted additional time-based features: year, month, day of week, and quarter.\n\n\nFeature Selection:\n\n- Removed irrelevant columns to focus the analysis on pertinent variables.\n- Retained features: pollutant, aqi, wind\n\n\nMissing Value Treatment:\n\n- Identified columns with missing values: most all of them\n- Applied mean() imputation method for numerical columns.\n- For categorical columns: n/a\n\n\nData Types and Memory Usage:\n\n- Optimized data types to reduce memory usage (e.g., using categories for low-cardinality strings, int8/int16 for small integers).\n\nBasic Statistics:\n\n- Generated summary statistics for numerical columns using df.describe().\n- Calculated frequency distributions for categorical variables.\n\n\nDistribution Analysis:\n\n- Plotted histograms and kernel density estimates for main numerical features.\n\n\nTime Series Components:\n\n- Decomposed time series data into trend, seasonality, and residual components for relevant variables.\n\n# Sweetviz Data Report\n\n::: {#cell-sweetvis-report .cell execution_count=9}\n\n::: {#sweetvis-report .cell-output .cell-output-display}\n```{=html}\n<script type=\"application/vnd.jupyter.widget-view+json\">\n{\"model_id\":\"4327aa9a215844d1960793bffa4990b1\",\"version_major\":2,\"version_minor\":0,\"quarto_mimetype\":\"application/vnd.jupyter.widget-view+json\"}\n</script>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nReport SWEETVIZ_REPORT.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n```\n:::\n:::\n\n\nWe have generated a complete statistical report confirming the quality of EDA steps.\n\n# Advanced Exploratory Data Analysis\nWe have also employed the ydata-profiling package, a powerful Time Series Analysis EDA package that offers more detailed analysis.\n\nWe have unlocked time series-specific features using ydata-profiling:\n- Set tsmode=True when creating the ProfileReport\n- Ensure our DataFrame is sorted or specify the sortby parameter\n- Time Series Feature Identification\n\nThe ydata identifies time-dependent features using autocorrelation analysis.  \nFor recognized time series features:\n- Histograms are replaced with line plots\n- Feature details include new autocorrelation and partial autocorrelation plots\n- Two additional warnings may appear: `NON STATIONARY` and `SEASONAL`\n\nHandling Multi-Entity Time Series Data, In our case, with category_id:\n\n- Each pollutants represents a distinct time series\n- For optimal analysis, we filter and profile each pollutant separately\n\n\n\n\n\n\n\nOur exploratory data analysis (EDA) process consisted of two complementary approaches:\n\n- *Manual Investigation*: We conducted an in-depth, hands-on examination of the dataset.\n- *Automated Analysis*: We leveraged two powerful EDA packages:\n\n- *Sweetviz*: For quick, visual data summaries\n- *ydata-profiling*: For more detailed, customizable reports  \n\nThese methods allowed us to thoroughly evaluate key data quality aspects, including:\n\n- Class balance in categorical variables\n- Presence and distribution of missing values (NaN)\n- Feature distributions and correlations\n- Potential time-series characteristics\n\nThis multi-faceted approach ensures a robust understanding of our dataset's structure, quality, and potential challenges before proceeding with further analysis.\n\n\n\n# Time Series Visualization for CO Pollutant, Wind and AQI\nCO pollutant refers to carbon monoxide, which is a colorless, odorless, and tasteless gas that can be harmful to human health and the environment. Here's some key information about CO as a pollutant:\n\nPrimarily produced by incomplete combustion of carbon-containing fuels\nMajor sources include vehicle exhaust, industrial processes, and some natural sources like volcanoes\n\n- Slightly less dense than air\n- Highly flammable\n\n::: {#ts-wind-co-aqi .cell execution_count=14}\n\n::: {#ts-wind-co-aqi-1 .cell-output .cell-output-display}\n```\n<Figure size 1000x1800 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/ts-wind-co-aqi-output-2.png){#ts-wind-co-aqi-2 width=3689 height=1179}\n:::\n:::\n\n\n# Time Series Visualization for SO2, NO2 and Ozone\nNO2 (nitrogen dioxide) is an important air pollutant. Here's a concise overview of it:  \n- Reddish-brown gas with a pungent odor\n- Part of a group of pollutants known as nitrogen oxides (NOx)\n\nSO2 (sulfur dioxide) is an important air pollutant. Here's a concise overview of SO2 as a pollutant:\n\n- Colorless gas with a sharp, pungent odor\n- Highly soluble in water\n\nOzone (O₃) as a pollutant is a complex topic, as it can be both beneficial and harmful depending on its location in the atmosphere. \nHere's a concise overview of ozone as a ground-level pollutant:\n\n- Colorless to pale blue gas with a distinctive smell\n- Highly reactive molecule composed of three oxygen atoms\n\n::: {#ts-so2-no2-ozone .cell execution_count=15}\n\n::: {#ts-so2-no2-ozone-1 .cell-output .cell-output-display}\n```\n<Figure size 1500x2000 with 0 Axes>\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/ts-so2-no2-ozone-output-2.png){#ts-so2-no2-ozone-2 width=3689 height=1767}\n:::\n:::\n\n\nWe finally completed the exploratory data analysis.\n\n\n# Results\n\n## Sci-Kit Learn Machine Learning\nUltimately, we want to see which variables have the greatest impact on AQI. To do this we must perform a machine learning analysis and create a prediction algorithm. \n\n\nFirst, missing data must be addressed. This can be done in a variety of ways, but for this we replace NA values with the mean for the respective city and group by week. If there is no data to take a mean of, that row will be dropped. \n\n\n\n\n\n\nSince AQI is the dependent variable being measured, all rows without AQI data are dropped. Certain cities have very little data and will be dropped out of necessity.\n\n\n\n\nThe data collected has separate information for the city of New York City. NYC is divided into five boroughs, each within its own county. These values are grouped and averaged out to make NYC have the same amount of datapoints as every other city. This will also address data present in some New York boroughs but not others. Likewise, Kansas City spans two states and two counties, so those values are grouped together.\n\n\n\n\nAfter this data cleaning, we are left with a total of eighteen cities across the country with a total metropolitan area population of greater than one million. The table below (figure 24324) shows all eighteen cities being used in the prediction algorithm and their respective row counts.\n\n::: {#cell-count-cities .cell execution_count=28}\n\n::: {#count-cities .cell-output .cell-output-display execution_count=28}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>city</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Boston</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Charlotte</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Cincinnati</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cleveland</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Dallas</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Detroit</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Houston</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Kansas City</td>\n      <td>241</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Los Angeles</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Memphis</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>New York City</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Phoenix</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Pittsburgh</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Portland</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Raleigh</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Seattle</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>St. Louis</td>\n      <td>418</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Washington</td>\n      <td>418</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nTo perform a ML prediction algorithm, the predicted variable (AQI) must be discrete. To achieve this, we bin AQI data into discrete groups. Initially, we thought to bin them based on the existing AQI categories, but found that most of the data is grouped in the sub 100 range. Therefore, we expanded the bins, focusing the prediction on outcomes in the double digits. The bins chosen are: \n\n- 0-30\n- 31-40\n- 41-50 \n- 51-60\n- 61-70\n- 71-80\n- 81-90\n- 91-100\n- 101-150\n- 151+\n\n\n\n\nA feature selector is run on the set of all variables. This chooses the best predictors of the dependent variable AQI.\n\n\nThe following tools are used:\n\n- Train Test Split\n- One Hot Encoder\n- Transformer\n- Pipeline\n- Standard Scaler \n\n\n\nFeature selection is done on the data. From this we are given the following variables: \n\n- City\n- Temperature\n- Humidity\n- Carbon Monoxide\n- Nitrogen Dioxide\n- Ozone\n- PM10\n- PM2.5\n\nThese features are used in the final model.\n\n\n\nWith these features, we test various models with default parameters to see which is the most accurate at predicting AQI from this dataset. The five models tested are: \n\n- K nearest neighbors\n- Tree model \n- Random Forest model\n- Logistic Regression \n- Naive Bayes \n\nRunning the models gives the output in figure 234324. Random Forest model is the most accurate and will be used for the final model.\n\n::: {#cell-model-select .cell execution_count=37}\n\n::: {#model-select .cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>Cohen Kappa Score</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>KNN</td>\n      <td>0.279682</td>\n      <td>0.451824</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Tree</td>\n      <td>0.390715</td>\n      <td>0.520958</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Random Forest</td>\n      <td>0.481175</td>\n      <td>0.602069</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Logistic</td>\n      <td>0.312286</td>\n      <td>0.485574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>naive Bayes</td>\n      <td>0.003825</td>\n      <td>0.048993</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n\n\nHyperparameter optimization will be done to further improve the model. A randomized search is run with 100 iterations. The following hyperparameters are optimized:\n\n- Max Categories\n- Min Frequency\n- Max Depth\n- Max Features\n- Min Samples Leaf\n- Min Samples Split\n- Num Estimators\n- Bootstrap\n\n\n\nFigure 242442 below shows the selected hyperparameters.\n\n::: {#cell-randsearch-get-params .cell execution_count=42}\n\n::: {#randsearch-get-params .cell-output .cell-output-display}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Parameter</th>\n      <th>Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>RF_model__bootstrap</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RF_model__max_depth</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>RF_model__max_features</td>\n      <td>sqrt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RF_model__min_samples_leaf</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RF_model__min_samples_split</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>RF_model__n_estimators</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>aqi_transformer__categories__max_categories</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>aqi_transformer__categories__min_frequency</td>\n      <td>15</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\nUsing these hyperparameters, we reach an accuracy of about 63%.\n\n::: {#cell-predict-X_test .cell execution_count=43}\n\n::: {.cell-output .cell-output-stdout}\n```\nCohen Kappa Score:  0.5344227699027316\nAccuracy:  0.643440391943386\n```\n:::\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/predict-x_test-output-2.png){#predict-x_test width=580 height=500}\n:::\n:::\n\n\nWe can use this model for the prediction of AQI, exploring the features that predict it, and use that to generate conclusions for what particles to reduce or systems to increase.\n\n\n---\n\nformat:\n  html:\n    code-fold: true\n    code-tools:\n      source: repo\n      #toggle: true\n      caption: \"Python\"\n    smooth-scroll: true\n    toc: true\n    toc-title: Contents\n    number-sections: false\n    html-math-method: mathjax\n    #css: styles.css\nexecute:\n  echo: false\n  warning: false\njupyter: python3\n\n---\n# ML Time Series with SARIMAX Model\n\n\n\n\n\n\n\nAny time series is decomposed of two things:\n\n- Seasonality\n- Trends\n\nBy the help of `statsmodel` package we can break the time series into its seasonal pattern and trends.\nThis will helps us to understand the data clearly and will help us to make more sense of the data.\n\n# Decomposing the Time Series With Additive Method\n\n::: {#cell-additive-decomp .cell execution_count=47}\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/additive-decomp-output-1.png){#additive-decomp width=684 height=484}\n:::\n:::\n\n\nThere are three components to a time series: \n\n1. `Trend`: Trend tells you how things are overall changing  \n2. `Seasonality`: Seasonality shows you how things change within a given period (e.g. year,month, week, day)  \n3. `Residual`: The Error/residual/irregular activity are the anomalies whitch cannot be explained by the trend or the seasonal value  \n\nIn a additive time series, the components add together to make the time series. If you have an increasing trend, you still\nsee roughly the same size peaks and troughs throughout the time series. This is often seen in indexed time series where the\nabsolute value is growing but changes stay relative.\n\n\n## Time Series Prediction\nFor this project, we have used an extended version of *ARIMA* model knows as *SARIMAX* model as we have explained in the methods section.\nThe *SARIMAX* model is used when the data sets have seasonal cycles. In our dataset concerning air quality/AQI there is a seasonal pattern\nwhich we can see in the above visualization.\n\nWe need to find the right p,d and q parameters to correctly forecast and predict the AQI value.\n\n- *p* is the auto-regressive part of the model. It allows us to incorporate the effect of past values into our model.\n- *d* is the integrated part of the model. This includes terms in the model that incorporate the amount of diferencing (the number of past time points to subtract from the current value) to apply the time series.\n- *q* is the moving average part of the model. This allows us to set the error of our model as a linear combination of the error values observed at previous time points in the past.  \n\nWe use a tuning technique called `grid search method` that attempts to compute the optimum values of hyperparameters. We are trying to find the right p,d,q values that would be given as an input to the SARIMAX time series model.\n\n::: {#grid-search .cell cache='true' execution_count=48}\n\n::: {.cell-output .cell-output-stdout}\n```\nARIMA(0, 0, 0)x(0, 0, 0, 12) - AIC:969.5419650946665\nARIMA(0, 0, 0)x(0, 0, 1, 12) - AIC:799.0140026908043\nARIMA(0, 0, 0)x(0, 1, 0, 12) - AIC:701.7072455506197\nARIMA(0, 0, 0)x(0, 1, 1, 12) - AIC:568.3211239351035\nARIMA(0, 0, 0)x(1, 0, 0, 12) - AIC:708.2727189545345\nARIMA(0, 0, 0)x(1, 0, 1, 12) - AIC:660.9171130206936\nARIMA(0, 0, 0)x(1, 1, 0, 12) - AIC:596.1563221105039\nARIMA(0, 0, 0)x(1, 1, 1, 12) - AIC:571.8620221843147\nARIMA(0, 0, 1)x(0, 0, 0, 12) - AIC:888.4893265461405\nARIMA(0, 0, 1)x(0, 0, 1, 12) - AIC:754.7451219152275\nARIMA(0, 0, 1)x(0, 1, 0, 12) - AIC:695.0468020327725\nARIMA(0, 0, 1)x(0, 1, 1, 12) - AIC:563.3526496700842\nARIMA(0, 0, 1)x(1, 0, 0, 12) - AIC:708.3487691701486\nARIMA(0, 0, 1)x(1, 0, 1, 12) - AIC:655.8968840891383\nARIMA(0, 0, 1)x(1, 1, 0, 12) - AIC:598.1490374699148\nARIMA(0, 0, 1)x(1, 1, 1, 12) - AIC:566.3367865157978\nARIMA(0, 1, 0)x(0, 0, 0, 12) - AIC:769.1876196189784\nARIMA(0, 1, 0)x(0, 0, 1, 12) - AIC:681.4253047727481\nARIMA(0, 1, 0)x(0, 1, 0, 12) - AIC:740.3973501203114\nARIMA(0, 1, 0)x(0, 1, 1, 12) - AIC:606.0067883430007\nARIMA(0, 1, 0)x(1, 0, 0, 12) - AIC:688.9276375883021\nARIMA(0, 1, 0)x(1, 0, 1, 12) - AIC:683.2372837276466\nARIMA(0, 1, 0)x(1, 1, 0, 12) - AIC:637.9760649104885\nARIMA(0, 1, 0)x(1, 1, 1, 12) - AIC:607.9989487123431\nARIMA(0, 1, 1)x(0, 0, 0, 12) - AIC:717.0512101206406\nARIMA(0, 1, 1)x(0, 0, 1, 12) - AIC:636.373429528529\nARIMA(0, 1, 1)x(0, 1, 0, 12) - AIC:692.512410906277\nARIMA(0, 1, 1)x(0, 1, 1, 12) - AIC:559.6920424480529\nARIMA(0, 1, 1)x(1, 0, 0, 12) - AIC:650.5293595230056\nARIMA(0, 1, 1)x(1, 0, 1, 12) - AIC:638.1908637932411\nARIMA(0, 1, 1)x(1, 1, 0, 12) - AIC:594.940391452659\nARIMA(0, 1, 1)x(1, 1, 1, 12) - AIC:562.5484300875305\nARIMA(1, 0, 0)x(0, 0, 0, 12) - AIC:775.150570595756\nARIMA(1, 0, 0)x(0, 0, 1, 12) - AIC:688.1982167211085\nARIMA(1, 0, 0)x(0, 1, 0, 12) - AIC:702.425519762607\nARIMA(1, 0, 0)x(0, 1, 1, 12) - AIC:570.1689904036024\nARIMA(1, 0, 0)x(1, 0, 0, 12) - AIC:688.2931195730088\nARIMA(1, 0, 0)x(1, 0, 1, 12) - AIC:662.6749372683774\nARIMA(1, 0, 0)x(1, 1, 0, 12) - AIC:590.7883988000217\nARIMA(1, 0, 0)x(1, 1, 1, 12) - AIC:573.825547011459\nARIMA(1, 0, 1)x(0, 0, 0, 12) - AIC:725.2611476282008\nARIMA(1, 0, 1)x(0, 0, 1, 12) - AIC:644.4595774810737\nARIMA(1, 0, 1)x(0, 1, 0, 12) - AIC:696.6355146715679\nARIMA(1, 0, 1)x(0, 1, 1, 12) - AIC:565.337721591011\nARIMA(1, 0, 1)x(1, 0, 0, 12) - AIC:651.3742765976529\nARIMA(1, 0, 1)x(1, 0, 1, 12) - AIC:657.7255114881699\nARIMA(1, 0, 1)x(1, 1, 0, 12) - AIC:592.7702867201957\nARIMA(1, 0, 1)x(1, 1, 1, 12) - AIC:567.3861300859227\nARIMA(1, 1, 0)x(0, 0, 0, 12) - AIC:750.4532664961456\nARIMA(1, 1, 0)x(0, 0, 1, 12) - AIC:665.693748389872\nARIMA(1, 1, 0)x(0, 1, 0, 12) - AIC:720.7807876037391\nARIMA(1, 1, 0)x(0, 1, 1, 12) - AIC:588.6301637485213\nARIMA(1, 1, 0)x(1, 0, 0, 12) - AIC:665.7141239363682\nARIMA(1, 1, 0)x(1, 0, 1, 12) - AIC:667.6890275833365\nARIMA(1, 1, 0)x(1, 1, 0, 12) - AIC:611.4437482645567\nARIMA(1, 1, 0)x(1, 1, 1, 12) - AIC:590.6185673644065\nARIMA(1, 1, 1)x(0, 0, 0, 12) - AIC:717.3211552781574\nARIMA(1, 1, 1)x(0, 0, 1, 12) - AIC:636.7110296932944\nARIMA(1, 1, 1)x(0, 1, 0, 12) - AIC:693.1696490581699\nARIMA(1, 1, 1)x(0, 1, 1, 12) - AIC:561.5301944999834\nARIMA(1, 1, 1)x(1, 0, 0, 12) - AIC:643.9735168529521\nARIMA(1, 1, 1)x(1, 0, 1, 12) - AIC:638.640931561371\nARIMA(1, 1, 1)x(1, 1, 0, 12) - AIC:588.5992832053371\nARIMA(1, 1, 1)x(1, 1, 1, 12) - AIC:564.5468753697722\n```\n:::\n:::\n\n\nWe have to find the lowest AIC values which would have the best corresponding p,d,q values to have the best forecast of AQI values.  \n\n## Summary of SARIMAX\n\n::: {#mod-fit .cell execution_count=49}\n\n::: {.cell-output .cell-output-stdout}\n```\n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.0483      0.306      0.158      0.875      -0.551       0.648\nma.L1         -1.0000    924.523     -0.001      0.999   -1813.031    1811.031\nma.S.L12      -1.0000   2355.498     -0.000      1.000   -4617.692    4615.692\nsigma2       134.1503   3.35e+05      0.000      1.000   -6.57e+05    6.57e+05\n==============================================================================\n```\n:::\n:::\n\n\n# How Fit the SARIMAX model\n## Print the summary which includes AIC\n\n::: {#fit-summary-aic .cell execution_count=50}\n\n::: {.cell-output .cell-output-stdout}\n```\n                                     SARIMAX Results                                      \n==========================================================================================\nDep. Variable:                                aqi   No. Observations:                   96\nModel:             SARIMAX(1, 1, 1)x(0, 1, 1, 12)   Log Likelihood                -276.765\nDate:                            Mon, 05 Aug 2024   AIC                            561.530\nTime:                                    14:12:52   BIC                            570.467\nSample:                                01-31-2015   HQIC                           565.076\n                                     - 12-31-2022                                         \nCovariance Type:                              opg                                         \n==============================================================================\n                 coef    std err          z      P>|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nar.L1          0.0483      0.306      0.158      0.875      -0.551       0.648\nma.L1         -1.0000    924.523     -0.001      0.999   -1813.031    1811.031\nma.S.L12      -1.0000   2355.498     -0.000      1.000   -4617.692    4615.692\nsigma2       134.1503   3.35e+05      0.000      1.000   -6.57e+05    6.57e+05\n===================================================================================\nLjung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):              2571.65\nProb(Q):                              1.00   Prob(JB):                         0.00\nHeteroskedasticity (H):               1.11   Skew:                             4.63\nProb(H) (two-sided):                  0.81   Kurtosis:                        31.44\n===================================================================================\n\nWarnings:\n[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n```\n:::\n:::\n\n\n::: {#extract-aic-value .cell execution_count=51}\n\n::: {.cell-output .cell-output-stdout}\n```\nThe AIC value is: 561.5301944999834\n```\n:::\n:::\n\n\n# Plot Diagnostics\n\n::: {#plot-diag .cell execution_count=52}\n\n::: {.cell-output .cell-output-display execution_count=52}\n![](capstone_files/figure-html/plot-diag-output-1.png){#plot-diag-1 width=1001 height=859}\n:::\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/plot-diag-output-2.png){#plot-diag-2 width=1001 height=859}\n:::\n:::\n\n\n# Train and Test\nRigorous validation is paramount to establishing the model's reliability and practical application. To ensure the model's generalizability, we will employ a train-test split. This approach safeguards against overfitting by exposing the model to unseen data, allowing for a more accurate assessment of its predictive capabilities.\n\nBy partitioning the dataset, we can:\n\n- Evaluate performance: Measure the model's accuracy on unseen data.\n- Detect overfitting: Identify discrepancies between training and testing performance.\n- Assess generalization: Determine the model's ability to handle new data.\n- Quantify reliability: Calculate confidence intervals for prediction accuracy.\n- Iteratively improve: Use insights to refine the model.\n\nThis rigorous process underpins the credibility and utility of our research findings.\n\nTo split the data, we follow the recommended `70:30` ratio, 70% of the data is the training data, and 30% of the data is the testing data.\n\n\n\n\n\nOnce the model is created, predicted values are generated using the .get_prediction() method, with datetime as input\n\n\n\nThe graph indicates overlapping patterns in the testing and training data, suggesting strong potential for the forecasting model's performance.\n\n::: {#cell-plot-prediction .cell execution_count=56}\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/plot-prediction-output-1.png){#plot-prediction width=1181 height=607}\n:::\n:::\n\n\nTo facilitate comparison of true and predicted test values, we will create a separate DataFrame. \nMean Error Estimation will be used for analysis.\n\n\n\nTo evaluate model performance, we calculate the MSE\n\n::: {#calculate-mse .cell execution_count=58}\n\n::: {.cell-output .cell-output-stdout}\n```\nThe Mean Squared Error of our forecasts is 1.41\n```\n:::\n:::\n\n\n## Forecasting Future Values\n\nAs we conclude our modeling process, we generate predictions for the next 7 data points:\n\n1. **Model Information**: The `result` variable contains our fitted model's details.\n\n2. **Forecasting Method**: We use the `.get_forecast()` method on our model results.\n\n3. **Prediction Generation**: This method analyzes observed patterns in our data to project future values.\n\n4. **Output**: We obtain forecasts for the next 7 time points, representing predicted air quality levels.\n\nThis step transforms our analytical work into actionable insights for air quality management.\n\n\n\n## Visualizing Our Results: The Culmination of Our Analysis\n\nThe final and crucial step of our project is the creation of a comprehensive plot that encapsulates our complex analysis. This visualization serves as the key to understanding and interpreting our findings.\n\n### Interpreting the Forecast Plot\n\nOur plot consists of several key elements:\n\n1. **Observed Values (Blue Line)**\n   - Represents the actual, historical air quality measurements\n   - Provides a baseline for comparing our predictions\n\n2. **Forecasted Values (Orange Line)**\n   - Depicts the future air quality levels predicted by our SARIMAX Time Series Model\n   - Allows us to visualize potential trends and patterns in air quality\n\n3. **Confidence Interval (Shaded Region)**\n   - The shaded area around the forecast line represents the 95% Confidence Interval (CI)\n   - Indicates the range within which we can be 95% confident that the true future values will fall\n   - Wider intervals suggest greater uncertainty in the prediction\n\nThis visual representation not only summarizes our extensive data analysis but also provides a powerful tool for understanding potential future air quality trends. It bridges the gap between complex statistical models and actionable insights, making our findings accessible and meaningful to a broader audience.\n\n::: {#cell-plot-forecast .cell execution_count=60}\n\n::: {.cell-output .cell-output-display}\n![](capstone_files/figure-html/plot-forecast-output-1.png){#plot-forecast width=1164 height=607}\n:::\n:::\n\n\n# Conclusion\n\nAfter conducting our thorough research, we have landed on these specific recommendations. We found there are high seasonal trends where late summer/early fall tends to have the worst air quality. These numbers consistently show up each year, exasperated by the dry heat and lack of rainfall. As climate change raises temperatures and water sources dry up, wildfire season will continue to get worse over time. We must be aware of the nature of air quality and how it differs at different parts of the year. We should understand how the AQI works, and avoid being outside for too long when it reaches more dangerous levels.\n\nAir quality is significantly affected by various natural and unpredictable elements, including:\n\n- Weather conditions\n- Wind speed and direction\n- Temperature fluctuations\n- Humidity levels\n- Atmospheric pressure\n- Solar radiation intensity\n\nWith multiple factors we have no control over, it is important to do what we can for those factors we can impact.\n\nWe must focus on the variables that have the greatest impact on the AQI. These are city, temperature, humidity, CO, NO2, O3, PM10, and PM2.5. City, temperature, and humidity for the most part are out of our control. That leaves us with three criteria gasses and all particulate matter. The largest source of carbon monoxide, nitrogen dioxide, and ozone is the cars, trucks, and other vehicles we use daily (Environmental Protection Agency). We can lower our reliance on personal vehicles by utilizing public transportation, carpooling, walking, biking, increasing work from home to lower commutes when available, and overall be more considerate about if driving a car is necessary. We often drive unnecessarily, out of convenience or impatience. \n\nFor many Americans, personal vehicles are required. Many urban and suburban areas lack proper public transportation, or existing public transportation systems are inadequate, unreliable, and infrequent. Many towns and cities in the United States were designed for cars instead of for people. Fixing this will require a substantial overhaul, necessitating millions or billions of dollars in spending. This is not to say that we shouldn’t bother---any investment that increases the public transportation system’s usage decreases the amount of cars on the road. A small change is the first step in addressing the personal vehicle issue.\n\nIndustrial manufacturing processes and agriculture are significant polluters of the environment. We should invest in the research of more environmentally friendly manufacturing methods, working with materials that require less combustion, or are recyclable. Agricultural reduction starts with less of a reliance on red meat and the dairy industry, mainstays of the American diet. This will be a huge shift, taking combined efforts of the citizens, government, and food industry. As red meat and dairy consumption goes down, possibly due to the replacement with artificial or lab grown meat, less livestock will need to be kept, and less feeding crops will need to be grown (Congressional Budget Office). It will be a difficult transition but a necessary one.\n\nWildfires not only increase the particle matter in the air, but burn forests, causing long term damage to the soil. Particulate matter in the air makes it more difficult to breathe, which is reflected by the increased AQI levels. Not all forest fires are started by man made sources, but many are. Therefore, when in the woods, one should always obey fire restrictions, especially in the middle of the summer when it’s most dry. If fires are allowed, they should always be watched and never left unattended. They must always be properly extinguished and all embers must be cool to the touch before leaving. Campsites should be properly cleaned, and all tools used correctly. One should also stay on marked trails, avoiding trampling vegetation which can increase the risk of wildfire spreading (Oregon Wildfire Response and Recovery).\n\nOne of the largest limitations is Algorithm Dependence. This is the reliability of forecasts which are inherently tied to the chosen predictive algorithms. Different models may yield varying results, emphasizing the importance of algorithm selection and validation.\n\nWe must also be wary of geographical considerations. Our data analysis couldn't fully quantify the unique geographical features of Portland and the broader Willamette Valley region. In further analysis we should seek to understand: \n\n- The protective influence of surrounding mountain ranges\n- The impact on wind patterns and air circulation\n- The potential effects of wildfires on air quality\n\nThese geographical factors play a significant role in local air quality dynamics but were beyond the scope of our current data set. The impact of the geological features can be seen in the image below (figure 1414)\n\n![AirNow Map](https://github.com/wu-msds-capstones/Air-Quality-Index/blob/main/images/AirNow-Map.png?raw=true)\n\nBy recognizing these limitations, we can better interpret and apply our forecasting results, while also identifying areas for future research and data collection to enhance prediction accuracy.\n\nUltimately, we have a responsibility to take care of our planet and combat climate change. The worse climate conditions get, the more wildfires will spread, and the worse the air quality will become. As time goes on, with worsening air conditions, more people will catch and even die from preventable conditions sparked by poor air quality.  Water, pollution, food, and financial problems will get worse. One should look at what they can do to make a difference, support those who vouch to make larger changes, and encourage people they know to do the same. While the situation may seem dire, there is hope for progress through concerted and informed efforts.\n\n\n# Bibliography\n\nAmerican Lung Association, https://www.lung.org/research/sota/key-findings  \n\nAirly, https://airly.org/en/how-does-humidity-affect-air-quality-all-you-need-to-know/  \n\nAirnow.gov, https://www.airnow.gov/aqi/aqi-basics/using-air-quality-index  \n\nCalifornia Air Resources Board, https://ww2.arb.ca.gov/resources/carbon-monoxide-and-health  \n\nCenters for Disease Control and Prevention, Agency for Toxic Substances and Disease Registry, https://wwwn.cdc.gov/TSP/ToxFAQs/ToxFAQsDetails.aspx?faqid=396&toxid=69  \n\nCenters for Disease Control and Prevention, Agency for Toxic Substances and Disease Registry, https://wwwn.cdc.gov/TSP/MMG/MMGDetails.aspx?mmgid=249&toxid=46 \n\nCongressional Budget Office, https://www.cbo.gov/publication/60030\n\nEnvironmental Protection Agency, https://www.epa.gov/pm-pollution/particulate-matter-pm-basics \n\nEnvironmental Protection Agency, https://www.epa.gov/ground-level-ozone-pollution/health-effects-ozone-pollution \n\nEnvironmental Protection Agency, https://www.epa.gov/clean-air-act-overview/evolution-clean-air-act \n\nFederal Transit Administration, https://www.apta.com/research-technical-resources/transit-statistics/ntd-data-tables/  \n\nFuller, Landrigan, Balakrishnan, et al., https://www.thelancet.com/journals/lanplh/article/PIIS2542-5196(22)00090-0/fulltext \n\nJacobs, Burgess, Abbott, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5922205/  \n\nManisalidis, Stavropoulou, Stavropoulos, Bezirtzoglou, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7044178/ \n\nNational Oceanic and Atmospheric Administration, https://oceanservice.noaa.gov/facts/nautical-mile-knot.html  \n\nNational Weather Service, https://www.weather.gov/source/zhu/ZHU_Training_Page/winds/pressure_winds/Pressure.htm \n\nOregon Wildfire Response and Recovery, https://wildfire.oregon.gov/prevention \n\nWorld Health Organization, https://www.who.int/news-room/fact-sheets/detail/lead-poisoning-and-health \n\nZhang Et. Al. https://acp.copernicus.org/articles/18/15003/2018/  \n\nWorld Health Organization, https://www.who.int/news/item/25-03-2014-7-million-premature-deaths-annually-linked-to-air-pollution\n\n",
    "supporting": [
      "capstone_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n"
      ],
      "include-after-body": [
        "<script type=application/vnd.jupyter.widget-state+json>\n{\"state\":{\"00fe15299a4c49b18c4f2319d2fd4097\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"35a5c9c53a1b4b0cbba7d250568dec35\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":\"inline-flex\",\"flex\":null,\"flex_flow\":\"row wrap\",\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":\"100%\"}},\"4327aa9a215844d1960793bffa4990b1\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HBoxModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HBoxModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HBoxView\",\"box_style\":\"\",\"children\":[\"IPY_MODEL_e9ffe310755d480aa9610ce2f668fbf8\",\"IPY_MODEL_9487431393bb4e63bdc5dff6f44c04bb\",\"IPY_MODEL_5afbdb23345b42b8ac99b835c6c59798\"],\"layout\":\"IPY_MODEL_35a5c9c53a1b4b0cbba7d250568dec35\",\"tabbable\":null,\"tooltip\":null}},\"5afbdb23345b42b8ac99b835c6c59798\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_00fe15299a4c49b18c4f2319d2fd4097\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_9d43480b128e4a8fb79dabe7899081cb\",\"tabbable\":null,\"tooltip\":null,\"value\":\" [100%]   00:02 -&gt; (00:00 left)\"}},\"9114e9d55ae8439d86a484d64d27526c\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"9487431393bb4e63bdc5dff6f44c04bb\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"FloatProgressModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"FloatProgressModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"ProgressView\",\"bar_style\":\"success\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_cb76c103281142a9947329bbdefe834a\",\"max\":1,\"min\":0,\"orientation\":\"horizontal\",\"style\":\"IPY_MODEL_eafb32d05fd24d3a89816e893dc34cc5\",\"tabbable\":null,\"tooltip\":null,\"value\":1}},\"9d43480b128e4a8fb79dabe7899081cb\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"background\":null,\"description_width\":\"\",\"font_size\":null,\"text_color\":null}},\"aa632be29e734dbd9a4964fb1b4d3389\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":null,\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"cb76c103281142a9947329bbdefe834a\":{\"model_module\":\"@jupyter-widgets/base\",\"model_module_version\":\"2.0.0\",\"model_name\":\"LayoutModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/base\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"LayoutModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"LayoutView\",\"align_content\":null,\"align_items\":null,\"align_self\":null,\"border_bottom\":null,\"border_left\":null,\"border_right\":null,\"border_top\":null,\"bottom\":null,\"display\":null,\"flex\":\"2\",\"flex_flow\":null,\"grid_area\":null,\"grid_auto_columns\":null,\"grid_auto_flow\":null,\"grid_auto_rows\":null,\"grid_column\":null,\"grid_gap\":null,\"grid_row\":null,\"grid_template_areas\":null,\"grid_template_columns\":null,\"grid_template_rows\":null,\"height\":null,\"justify_content\":null,\"justify_items\":null,\"left\":null,\"margin\":null,\"max_height\":null,\"max_width\":null,\"min_height\":null,\"min_width\":null,\"object_fit\":null,\"object_position\":null,\"order\":null,\"overflow\":null,\"padding\":null,\"right\":null,\"top\":null,\"visibility\":null,\"width\":null}},\"e9ffe310755d480aa9610ce2f668fbf8\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"HTMLModel\",\"state\":{\"_dom_classes\":[],\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"HTMLModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/controls\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"HTMLView\",\"description\":\"\",\"description_allow_html\":false,\"layout\":\"IPY_MODEL_aa632be29e734dbd9a4964fb1b4d3389\",\"placeholder\":\"​\",\"style\":\"IPY_MODEL_9114e9d55ae8439d86a484d64d27526c\",\"tabbable\":null,\"tooltip\":null,\"value\":\"Done! Use &#x27;show&#x27; commands to display/save.   \"}},\"eafb32d05fd24d3a89816e893dc34cc5\":{\"model_module\":\"@jupyter-widgets/controls\",\"model_module_version\":\"2.0.0\",\"model_name\":\"ProgressStyleModel\",\"state\":{\"_model_module\":\"@jupyter-widgets/controls\",\"_model_module_version\":\"2.0.0\",\"_model_name\":\"ProgressStyleModel\",\"_view_count\":null,\"_view_module\":\"@jupyter-widgets/base\",\"_view_module_version\":\"2.0.0\",\"_view_name\":\"StyleView\",\"bar_color\":null,\"description_width\":\"\"}}},\"version_major\":2,\"version_minor\":0}\n</script>\n"
      ]
    }
  }
}